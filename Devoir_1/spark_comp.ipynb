{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn and Spark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[5]\").appName(\"MySparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Data is sourced from https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "Steps:\n",
    "- Load data into spark dataframe\n",
    "- Preprocess data (fill na)\n",
    "- Create embedings for categorical values\n",
    "- Assemble into a single feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
      "|_c0|              _c1|     _c2|       _c3| _c4|                _c5|               _c6|           _c7|   _c8|    _c9|  _c10|_c11|_c12|          _c13|  _c14|\n",
      "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
      "| 39|        State-gov| 77516.0| Bachelors|13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|2174.0| 0.0|40.0| United-States| <=50K|\n",
      "| 50| Self-emp-not-inc| 83311.0| Bachelors|13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|   0.0| 0.0|13.0| United-States| <=50K|\n",
      "| 38|          Private|215646.0|   HS-grad| 9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
      "| 53|          Private|234721.0|      11th| 7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
      "| 28|          Private|338409.0| Bachelors|13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|   0.0| 0.0|40.0|          Cuba| <=50K|\n",
      "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data into Spark DataFrame\n",
    "df = spark.read.csv('data_a/adult.data', header=False, inferSchema=True)\n",
    "\n",
    "# Fill NA\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:  ['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10', '_c11', '_c12', '_c13']\n",
      "Label column:  _c14\n"
     ]
    }
   ],
   "source": [
    "# Define the features and label columns\n",
    "feature_cols = df.columns[:-1]\n",
    "label_col = df.columns[-1]\n",
    "\n",
    "print(\"Feature columns: \", feature_cols)\n",
    "print(\"Label column: \", label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String indexers for categorical columns\n",
    "str_cols = [col for col in feature_cols if df.select(col).dtypes[0][1] == 'string']\n",
    "feature_indexers = [StringIndexer(inputCol=col, outputCol=col+'_index') for col in str_cols]\n",
    "\n",
    "# Get new feature column names\n",
    "feature_cols_indexed = [indexer.getOutputCol() for indexer in feature_indexers] + [col for col in feature_cols if col not in str_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String indexer for label\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe\n",
    "df_indexed = Pipeline(stages=feature_indexers+[labelIndexer]).fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+--------+----+------+----+----+\n",
      "|indexedLabel|_c1_index|_c3_index|_c5_index|_c6_index|_c7_index|_c8_index|_c9_index|_c13_index|_c0|_c2     |_c4 |_c10  |_c11|_c12|\n",
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+--------+----+------+----+----+\n",
      "|0.0         |4.0      |2.0      |1.0      |3.0      |1.0      |0.0      |0.0      |0.0       |39 |77516.0 |13.0|2174.0|0.0 |40.0|\n",
      "|0.0         |1.0      |2.0      |0.0      |2.0      |0.0      |0.0      |0.0      |0.0       |50 |83311.0 |13.0|0.0   |0.0 |13.0|\n",
      "|0.0         |0.0      |0.0      |2.0      |9.0      |1.0      |0.0      |0.0      |0.0       |38 |215646.0|9.0 |0.0   |0.0 |40.0|\n",
      "|0.0         |0.0      |5.0      |0.0      |9.0      |0.0      |1.0      |0.0      |0.0       |53 |234721.0|7.0 |0.0   |0.0 |40.0|\n",
      "|0.0         |0.0      |2.0      |0.0      |0.0      |4.0      |1.0      |1.0      |9.0       |28 |338409.0|13.0|0.0   |0.0 |40.0|\n",
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+--------+----+------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.select(\"indexedLabel\", *feature_cols_indexed).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all columns to integer type\n",
    "for column_name in feature_cols_indexed + [\"indexedLabel\"]:\n",
    "    df_indexed = df_indexed.withColumn(column_name, col(column_name).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+------+---+----+----+----+\n",
      "|indexedLabel|_c1_index|_c3_index|_c5_index|_c6_index|_c7_index|_c8_index|_c9_index|_c13_index|_c0|_c2   |_c4|_c10|_c11|_c12|\n",
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+------+---+----+----+----+\n",
      "|0           |4        |2        |1        |3        |1        |0        |0        |0         |39 |77516 |13 |2174|0   |40  |\n",
      "|0           |1        |2        |0        |2        |0        |0        |0        |0         |50 |83311 |13 |0   |0   |13  |\n",
      "|0           |0        |0        |2        |9        |1        |0        |0        |0         |38 |215646|9  |0   |0   |40  |\n",
      "|0           |0        |5        |0        |9        |0        |1        |0        |0         |53 |234721|7  |0   |0   |40  |\n",
      "|0           |0        |2        |0        |0        |4        |1        |1        |9         |28 |338409|13 |0   |0   |40  |\n",
      "+------------+---------+---------+---------+---------+---------+---------+---------+----------+---+------+---+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.select(\"indexedLabel\", *feature_cols_indexed).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols_indexed, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled = assembler.transform(df_indexed).select(\"features\", \"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+------------+\n",
      "|features                                                           |indexedLabel|\n",
      "+-------------------------------------------------------------------+------------+\n",
      "|[4.0,2.0,1.0,3.0,1.0,0.0,0.0,0.0,39.0,77516.0,13.0,2174.0,0.0,40.0]|0           |\n",
      "|(14,[0,1,3,8,9,10,13],[1.0,2.0,2.0,50.0,83311.0,13.0,13.0])        |0           |\n",
      "|(14,[2,3,4,8,9,10,13],[2.0,9.0,1.0,38.0,215646.0,9.0,40.0])        |0           |\n",
      "|(14,[1,3,5,8,9,10,13],[5.0,9.0,1.0,53.0,234721.0,7.0,40.0])        |0           |\n",
      "|[0.0,2.0,0.0,0.0,4.0,1.0,1.0,9.0,28.0,338409.0,13.0,0.0,0.0,40.0]  |0           |\n",
      "+-------------------------------------------------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "df_train = df_assembled.alias('df_train')\n",
    "\n",
    "# Bloat dataframe\n",
    "for _ in range(250):\n",
    "    df_train = df_train.union(df_assembled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import time\n",
    "\n",
    "# Create a DecisionTree model\n",
    "tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features')\n",
    "\n",
    "# Create a pipeline with the DecisionTree model\n",
    "pipeline = Pipeline(stages=[tree])\n",
    "\n",
    "# Define the parameter grid for cross-validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(tree.maxDepth, [1, 5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator with a 5-fold cross-validation\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel', predictionCol='prediction', metricName='accuracy')\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=5)\n",
    "\n",
    "dt = time.time()\n",
    "crossval = crossval.fit(df_train)\n",
    "dt = time.time() - dt\n",
    "\n",
    "print(f'Performance MLlib: {dt} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "# Create the DecisionTree model\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Separate your features (X) and target variable (y)\n",
    "X = df_train.drop('indexedLabel').collect()\n",
    "y = df_train['indexedLabel'].values\n",
    "\n",
    "# Fit the model to the data and calculate performance\n",
    "dt = time.time()\n",
    "scores = cross_val_score(tree, X, y, cv=5, scoring='accuracy')\n",
    "dt = time.time() - dt\n",
    "\n",
    "print(f'Performance scikit-learn: {dt} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-8inf919-aDMhdl4N-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
