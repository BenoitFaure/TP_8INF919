{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn and Spark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[5]\").appName(\"MySparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Data is sourced from https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "Steps:\n",
    "- Load data into spark dataframe\n",
    "- Preprocess data (fill na)\n",
    "- Create embedings for categorical values\n",
    "- Assemble into a single feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into Spark DataFrame\n",
    "df = spark.read.csv('data_a/adult.data', header=False, inferSchema=True)\n",
    "\n",
    "# Fill NA\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and label columns\n",
    "feature_cols = df.columns[:-1]\n",
    "label_col = df.columns[-1]\n",
    "\n",
    "print(\"Feature columns: \", feature_cols)\n",
    "print(\"Label column: \", label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String indexers for categorical columns\n",
    "str_cols = [col for col in feature_cols if df.select(col).dtypes[0][1] == 'string']\n",
    "feature_indexers = [StringIndexer(inputCol=col, outputCol=col+'_index') for col in str_cols]\n",
    "\n",
    "# Get new feature column names\n",
    "feature_cols_indexed = [indexer.getOutputCol() for indexer in feature_indexers] + [col for col in feature_cols if col not in str_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String indexer for label\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe\n",
    "df_indexed = Pipeline(stages=feature_indexers+[labelIndexer]).fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed.select(\"indexedLabel\", *feature_cols_indexed).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all columns to integer type\n",
    "for column_name in feature_cols_indexed + [\"indexedLabel\"]:\n",
    "    df_indexed = df_indexed.withColumn(column_name, col(column_name).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed.select(\"indexedLabel\", *feature_cols_indexed).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols_indexed, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled = assembler.transform(df_indexed).select(\"features\", \"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dataframe\n",
    "df_train = df_assembled.alias('df_train')\n",
    "\n",
    "# Bloat dataframe\n",
    "for _ in range(250):\n",
    "    df_train = df_train.union(df_assembled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import time\n",
    "\n",
    "# Create a DecisionTree model\n",
    "tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features')\n",
    "\n",
    "# Create a pipeline with the DecisionTree model\n",
    "pipeline = Pipeline(stages=[tree])\n",
    "\n",
    "# Define the parameter grid for cross-validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(tree.maxDepth, [1, 5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator with a 5-fold cross-validation\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel', predictionCol='prediction', metricName='accuracy')\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=5)\n",
    "\n",
    "dt = time.time()\n",
    "crossval = crossval.fit(df_train)\n",
    "dt = time.time() - dt\n",
    "\n",
    "print(f'Performance MLlib: {dt} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "# Create the DecisionTree model\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Separate your features (X) and target variable (y)\n",
    "X = df_train.drop('indexedLabel').collect()\n",
    "y = df_train['indexedLabel'].values\n",
    "\n",
    "# Fit the model to the data and calculate performance\n",
    "dt = time.time()\n",
    "scores = cross_val_score(tree, X, y, cv=5, scoring='accuracy')\n",
    "dt = time.time() - dt\n",
    "\n",
    "print(f'Performance scikit-learn: {dt} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-8inf919-aDMhdl4N-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
