{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n",
      "Number of classes:  10\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Print dimensions of training data\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "\n",
    "# Print dimensions of test data\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)\n",
    "\n",
    "# Print number of unique classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Number of classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images by 10 degrees\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,  # randomly shift images vertically by 10% of the height\n",
    "    zoom_range=0.1,  # randomly zoom images by 10%\n",
    "    horizontal_flip=True  # randomly flip images horizontally\n",
    ")\n",
    "\n",
    "data_gen_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the ImageDataGenerator on x_train\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # Generate augmented images\n",
    "# augmented_images = datagen.flow(x_train, y_train, batch_size=data_gen_batch_size)\n",
    "\n",
    "# # Iterate over the augmented images and append them to x_train\n",
    "# for i, (x_batch, y_batch) in enumerate(augmented_images):\n",
    "#     x_train = np.concatenate((x_train, x_batch), axis=0)\n",
    "#     y_train = np.concatenate((y_train, y_batch), axis=0)\n",
    "#     if i >= len(x_train) // data_gen_batch_size:\n",
    "#         break\n",
    "\n",
    "# # Print the new dimensions of x_train\n",
    "# print(\"New dimensions of x_train: \", x_train.shape)\n",
    "# print(\"New dimensions of y_train: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "resize = (32, 32) # (224, 224)\n",
    "\n",
    "# One hot encode labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Load as tf dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Normalize images\n",
    "def normalize_img(image, label):\n",
    "\n",
    "    # Resize images\n",
    "    image = tf.image.resize(image, resize)\n",
    "\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Normalise images\n",
    "ds_train = train_dataset.map(normalize_img)\n",
    "ds_test = test_dataset.map(normalize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout, \\\n",
    "    AveragePooling2D, BatchNormalization, Activation, Add, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomZoom, RandomFlip, RandomTranslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initializer\n",
    "initializer = tf.initializers.he_normal(seed=42) # tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=42)\n",
    "classification_initializer = tf.initializers.glorot_normal(seed=42)\n",
    "\n",
    "activation_function = 'relu' # 'selu'\n",
    "use_bias = False # Batch Norm takes care of it\n",
    "epsilon_bn = 1.001e-5\n",
    "kernel_reg = tf.keras.regularizers.l2(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resnet identity block\n",
    "\n",
    "def identity_block(filter, kernel_size=3):\n",
    "    def _identity_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "        \n",
    "        # Activation\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _identity_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resnet convolutional block\n",
    "\n",
    "def convolutional_res_block(filter, kernel_size=3):\n",
    "    def _convolutional_res_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Layer 3\n",
    "        input_x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(input_x)\n",
    "        input_x = BatchNormalization(axis=3, epsilon=epsilon_bn)(input_x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "        \n",
    "        # Activation\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _convolutional_res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduction Convolutional Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reduction convolutional block\n",
    "\n",
    "def reduction_convolutional_res_block(filter, kernel_size=3, strides=2):\n",
    "    def _reduction_convolutional_res_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Layer 3\n",
    "        input_x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(input_x)\n",
    "        input_x = BatchNormalization(axis=3, epsilon=epsilon_bn)(input_x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _reduction_convolutional_res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block\n",
    "def convolutional_block(filter, kernel_size=3, strides=2):\n",
    "    def _convolutional_block(x):\n",
    "        \n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _convolutional_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = [\n",
    "    RandomRotation(0.3, seed=42),\n",
    "    RandomTranslation(0.4, 0.4, seed=42),\n",
    "    RandomZoom(0.3, seed=42),\n",
    "    RandomFlip(seed=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = [\n",
    "    RandomRotation(0.1, seed=42),\n",
    "    RandomTranslation(0.1, 0.1, seed=42),\n",
    "    RandomZoom(0.1, seed=42),\n",
    "    RandomFlip(seed=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_1_data_augmentation'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64),\n",
    "    identity_block(64),\n",
    "    reduction_convolutional_res_block(128),\n",
    "    identity_block(128),\n",
    "    reduction_convolutional_res_block(256),\n",
    "    identity_block(256),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    identity_block(512),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    AveragePooling2D(pool_size=4, strides=4, padding='same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_3'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64),\n",
    "    identity_block(64),\n",
    "    identity_block(64),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(128),\n",
    "    identity_block(128),\n",
    "    identity_block(128),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(256),\n",
    "    identity_block(256),\n",
    "    identity_block(256),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(512, kernel_size=1),\n",
    "    identity_block(512, kernel_size=1),\n",
    "    identity_block(512, kernel_size=1),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_4'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "    AveragePooling2D(pool_size=3, strides = 2, padding = 'same'),\n",
    "    \n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=(4, 4), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(512),\n",
    "    \n",
    "    convolutional_block(512, kernel_size = 3, strides = 2),\n",
    "    AveragePooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_small_tests'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "\n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=2, padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    AveragePooling2D(pool_size=2, padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=4, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_4_32'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "\n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=(4, 4), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(512),\n",
    "    \n",
    "    convolutional_block(512, kernel_size = 1, strides = 1),\n",
    "    AveragePooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_5'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "    MaxPooling2D(pool_size=3, strides = 2, padding = 'same'),\n",
    "\n",
    "    identity_block(64),\n",
    "    identity_block(64),\n",
    "\n",
    "    convolutional_block(128),\n",
    "    identity_block(128),\n",
    "\n",
    "    convolutional_block(256),\n",
    "    identity_block(256),\n",
    "\n",
    "    convolutional_block(512),\n",
    "    identity_block(512),\n",
    "\n",
    "    AveragePooling2D(pool_size=7)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet9'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 3, strides = 1),\n",
    "\n",
    "    convolutional_block(128, kernel_size = 3, strides = 1),\n",
    "    MaxPooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "    \n",
    "    identity_block(128),\n",
    "\n",
    "    convolutional_block(256, kernel_size = 3, strides = 1),\n",
    "    MaxPooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "\n",
    "    convolutional_block(512, kernel_size = 3, strides = 1),\n",
    "    MaxPooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "\n",
    "    identity_block(512),\n",
    "    MaxPooling2D(pool_size=4, strides = 4, padding = 'same')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_name = None\n",
    "if False:\n",
    "    model_name = 'resnet_4_1'\n",
    "    load_model_name = 'resnet_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_net = [\n",
    "    Flatten(),\n",
    "    Dense(512, kernel_initializer=initializer, activation=activation_function),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, kernel_initializer=classification_initializer, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_net = [\n",
    "    Flatten(),\n",
    "    Dense(num_classes, kernel_initializer=classification_initializer, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile mondel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "input_shape = (resize[0], resize[1], 3)\n",
    "input_layer = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "\n",
    "    def compile_layers(input, layers):\n",
    "        for layer in layers:\n",
    "            input = layer(input)\n",
    "        return input\n",
    "    \n",
    "    # Build Data augmentation\n",
    "    data_augmentation_layers = compile_layers(input_layer, data_aug)\n",
    "\n",
    "    # Build Feature Extractor\n",
    "    conv_net_layers = compile_layers(data_augmentation_layers, conv_net)\n",
    "\n",
    "    # Build Classifier\n",
    "    classification_layers = compile_layers(conv_net_layers, classification_net)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=classification_layers)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model_name is not None:\n",
    "    model.load_weights('models/' + load_model_name + '.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "random_rotation_3 (RandomRotati (None, 32, 32, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "random_translation_3 (RandomTra (None, 32, 32, 3)    0           random_rotation_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "random_zoom_3 (RandomZoom)      (None, 32, 32, 3)    0           random_translation_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "random_flip_3 (RandomFlip)      (None, 32, 32, 3)    0           random_zoom_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1728        random_flip_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  73728       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147456      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  294912      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 256)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    1179648     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 512)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 512)    2359296     max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 512)    2359296     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 512)    0           batch_normalization_15[0][0]     \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 512)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 512)          0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           5130        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,577,610\n",
      "Trainable params: 6,573,130\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# Train settings\n",
    "epochs = 200\n",
    "batch_size = 64 # 8\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 0.005\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, clipvalue=0.1)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset for Performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# ds_train = ds_train.cache()\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "del x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(label_smoothing=0.2), metrics=['accuracy'])\n",
    "\n",
    "    # Save model callback\n",
    "    checkpoint = ModelCheckpoint('models/' + model_name + '.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "    # Tensorboard callback\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_' + model_name\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    print('tensorboard --logdir ' + log_dir)\n",
    "\n",
    "    # Train model\n",
    "    run_hist = model.fit(ds_train, validation_data=ds_test,\n",
    "                         epochs=epochs, batch_size=batch_size,\n",
    "                         callbacks=[checkpoint, tensorboard_callback])\n",
    "    \n",
    "    return run_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir logs/fit/20231123-214740_resnet9\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/782 [..............................] - ETA: 0s - loss: 4.8936 - accuracy: 0.0938WARNING:tensorflow:From c:\\Users\\benoi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tp-8inf919-aDMhdl4N-py3.8\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/782 [..............................] - ETA: 44s - loss: 6.7040 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0257s vs `on_train_batch_end` time: 0.0894s). Check your callbacks.\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.3659 - accuracy: 0.2904\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33200, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 2.3659 - accuracy: 0.2904 - val_loss: 2.7472 - val_accuracy: 0.3320\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.9585 - accuracy: 0.4348\n",
      "Epoch 00002: val_accuracy improved from 0.33200 to 0.47730, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 1.9585 - accuracy: 0.4348 - val_loss: 1.8792 - val_accuracy: 0.4773\n",
      "Epoch 3/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.7581 - accuracy: 0.5204\n",
      "Epoch 00003: val_accuracy improved from 0.47730 to 0.54640, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.7583 - accuracy: 0.5204 - val_loss: 1.7205 - val_accuracy: 0.5464\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.6439 - accuracy: 0.5812\n",
      "Epoch 00004: val_accuracy improved from 0.54640 to 0.59180, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.6439 - accuracy: 0.5812 - val_loss: 1.6246 - val_accuracy: 0.5918\n",
      "Epoch 5/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.5682 - accuracy: 0.6255\n",
      "Epoch 00005: val_accuracy did not improve from 0.59180\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.5682 - accuracy: 0.6255 - val_loss: 1.6725 - val_accuracy: 0.5742\n",
      "Epoch 6/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.6546\n",
      "Epoch 00006: val_accuracy did not improve from 0.59180\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.5140 - accuracy: 0.6546 - val_loss: 1.6810 - val_accuracy: 0.5462\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.4758 - accuracy: 0.6806\n",
      "Epoch 00007: val_accuracy improved from 0.59180 to 0.63690, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.4758 - accuracy: 0.6806 - val_loss: 1.5548 - val_accuracy: 0.6369\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.4386 - accuracy: 0.7002\n",
      "Epoch 00008: val_accuracy improved from 0.63690 to 0.68640, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.4386 - accuracy: 0.7002 - val_loss: 1.4842 - val_accuracy: 0.6864\n",
      "Epoch 9/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.4058 - accuracy: 0.7192\n",
      "Epoch 00009: val_accuracy improved from 0.68640 to 0.70710, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.4058 - accuracy: 0.7192 - val_loss: 1.4148 - val_accuracy: 0.7071\n",
      "Epoch 10/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.7339\n",
      "Epoch 00010: val_accuracy did not improve from 0.70710\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.3780 - accuracy: 0.7339 - val_loss: 1.4582 - val_accuracy: 0.6806\n",
      "Epoch 11/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3535 - accuracy: 0.7485\n",
      "Epoch 00011: val_accuracy did not improve from 0.70710\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.3535 - accuracy: 0.7485 - val_loss: 1.4309 - val_accuracy: 0.7005\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.7595\n",
      "Epoch 00012: val_accuracy did not improve from 0.70710\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.3284 - accuracy: 0.7595 - val_loss: 1.4942 - val_accuracy: 0.6636\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3080 - accuracy: 0.7694\n",
      "Epoch 00013: val_accuracy improved from 0.70710 to 0.74020, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.3080 - accuracy: 0.7694 - val_loss: 1.3650 - val_accuracy: 0.7402\n",
      "Epoch 14/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2870 - accuracy: 0.7856\n",
      "Epoch 00014: val_accuracy did not improve from 0.74020\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.2870 - accuracy: 0.7855 - val_loss: 1.4329 - val_accuracy: 0.6956\n",
      "Epoch 15/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2697 - accuracy: 0.7947\n",
      "Epoch 00015: val_accuracy did not improve from 0.74020\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.2698 - accuracy: 0.7946 - val_loss: 1.4255 - val_accuracy: 0.7061\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2537 - accuracy: 0.8023\n",
      "Epoch 00016: val_accuracy did not improve from 0.74020\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.2537 - accuracy: 0.8023 - val_loss: 1.3823 - val_accuracy: 0.7245\n",
      "Epoch 17/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2388 - accuracy: 0.8107\n",
      "Epoch 00017: val_accuracy improved from 0.74020 to 0.75350, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.2389 - accuracy: 0.8107 - val_loss: 1.3390 - val_accuracy: 0.7535\n",
      "Epoch 18/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2226 - accuracy: 0.8190\n",
      "Epoch 00018: val_accuracy did not improve from 0.75350\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.2226 - accuracy: 0.8190 - val_loss: 1.3340 - val_accuracy: 0.7511\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2127 - accuracy: 0.8249\n",
      "Epoch 00019: val_accuracy did not improve from 0.75350\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.2127 - accuracy: 0.8249 - val_loss: 1.4010 - val_accuracy: 0.7195\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1994 - accuracy: 0.8329\n",
      "Epoch 00020: val_accuracy improved from 0.75350 to 0.76050, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1994 - accuracy: 0.8329 - val_loss: 1.3148 - val_accuracy: 0.7605\n",
      "Epoch 21/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1895 - accuracy: 0.8370\n",
      "Epoch 00021: val_accuracy did not improve from 0.76050\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1896 - accuracy: 0.8370 - val_loss: 1.3405 - val_accuracy: 0.7511\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1803 - accuracy: 0.8425\n",
      "Epoch 00022: val_accuracy did not improve from 0.76050\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1803 - accuracy: 0.8425 - val_loss: 1.3452 - val_accuracy: 0.7473\n",
      "Epoch 23/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1701 - accuracy: 0.8489\n",
      "Epoch 00023: val_accuracy did not improve from 0.76050\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1701 - accuracy: 0.8488 - val_loss: 1.3344 - val_accuracy: 0.7573\n",
      "Epoch 24/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1624 - accuracy: 0.8536\n",
      "Epoch 00024: val_accuracy improved from 0.76050 to 0.76590, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 1.1624 - accuracy: 0.8535 - val_loss: 1.3097 - val_accuracy: 0.7659\n",
      "Epoch 25/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1495 - accuracy: 0.8601\n",
      "Epoch 00025: val_accuracy did not improve from 0.76590\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 1.1495 - accuracy: 0.8600 - val_loss: 1.3521 - val_accuracy: 0.7437\n",
      "Epoch 26/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1429 - accuracy: 0.8648\n",
      "Epoch 00026: val_accuracy did not improve from 0.76590\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.1429 - accuracy: 0.8648 - val_loss: 1.3560 - val_accuracy: 0.7427\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1377 - accuracy: 0.8670\n",
      "Epoch 00027: val_accuracy did not improve from 0.76590\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 1.1377 - accuracy: 0.8670 - val_loss: 1.3596 - val_accuracy: 0.7413\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1266 - accuracy: 0.8747\n",
      "Epoch 00028: val_accuracy improved from 0.76590 to 0.77810, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1266 - accuracy: 0.8747 - val_loss: 1.2982 - val_accuracy: 0.7781\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1224 - accuracy: 0.8754\n",
      "Epoch 00029: val_accuracy did not improve from 0.77810\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.1224 - accuracy: 0.8754 - val_loss: 1.2942 - val_accuracy: 0.7755\n",
      "Epoch 30/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1174 - accuracy: 0.8791\n",
      "Epoch 00030: val_accuracy improved from 0.77810 to 0.78480, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.1174 - accuracy: 0.8791 - val_loss: 1.2818 - val_accuracy: 0.7848\n",
      "Epoch 31/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1085 - accuracy: 0.8842\n",
      "Epoch 00031: val_accuracy did not improve from 0.78480\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.1085 - accuracy: 0.8842 - val_loss: 1.3347 - val_accuracy: 0.7517\n",
      "Epoch 32/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1042 - accuracy: 0.8872\n",
      "Epoch 00032: val_accuracy improved from 0.78480 to 0.78840, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 1.1041 - accuracy: 0.8872 - val_loss: 1.2699 - val_accuracy: 0.7884\n",
      "Epoch 33/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0986 - accuracy: 0.8906\n",
      "Epoch 00033: val_accuracy did not improve from 0.78840\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0986 - accuracy: 0.8906 - val_loss: 1.3558 - val_accuracy: 0.7447\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0924 - accuracy: 0.8929\n",
      "Epoch 00034: val_accuracy did not improve from 0.78840\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0924 - accuracy: 0.8929 - val_loss: 1.2978 - val_accuracy: 0.7774\n",
      "Epoch 35/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0897 - accuracy: 0.8962\n",
      "Epoch 00035: val_accuracy did not improve from 0.78840\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0897 - accuracy: 0.8962 - val_loss: 1.3184 - val_accuracy: 0.7676\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0823 - accuracy: 0.8984\n",
      "Epoch 00036: val_accuracy improved from 0.78840 to 0.80240, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0823 - accuracy: 0.8984 - val_loss: 1.2575 - val_accuracy: 0.8024\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.9006\n",
      "Epoch 00037: val_accuracy improved from 0.80240 to 0.80870, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0801 - accuracy: 0.9006 - val_loss: 1.2447 - val_accuracy: 0.8087\n",
      "Epoch 38/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0735 - accuracy: 0.9046\n",
      "Epoch 00038: val_accuracy did not improve from 0.80870\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 1.0735 - accuracy: 0.9046 - val_loss: 1.2818 - val_accuracy: 0.7864\n",
      "Epoch 39/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0707 - accuracy: 0.9062\n",
      "Epoch 00039: val_accuracy improved from 0.80870 to 0.81660, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0707 - accuracy: 0.9062 - val_loss: 1.2290 - val_accuracy: 0.8166\n",
      "Epoch 40/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0639 - accuracy: 0.9104\n",
      "Epoch 00040: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 1.0639 - accuracy: 0.9104 - val_loss: 1.2854 - val_accuracy: 0.7809\n",
      "Epoch 41/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0584 - accuracy: 0.9131\n",
      "Epoch 00041: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0584 - accuracy: 0.9131 - val_loss: 1.2740 - val_accuracy: 0.7922\n",
      "Epoch 42/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0563 - accuracy: 0.9139\n",
      "Epoch 00042: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0563 - accuracy: 0.9139 - val_loss: 1.2656 - val_accuracy: 0.7976\n",
      "Epoch 43/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0521 - accuracy: 0.9167\n",
      "Epoch 00043: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0521 - accuracy: 0.9167 - val_loss: 1.2624 - val_accuracy: 0.8047\n",
      "Epoch 44/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0494 - accuracy: 0.9194\n",
      "Epoch 00044: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0494 - accuracy: 0.9194 - val_loss: 1.2615 - val_accuracy: 0.8018\n",
      "Epoch 45/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0453 - accuracy: 0.9210\n",
      "Epoch 00045: val_accuracy did not improve from 0.81660\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0453 - accuracy: 0.9210 - val_loss: 1.2465 - val_accuracy: 0.8045\n",
      "Epoch 46/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0408 - accuracy: 0.9239\n",
      "Epoch 00046: val_accuracy improved from 0.81660 to 0.83250, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0408 - accuracy: 0.9239 - val_loss: 1.2039 - val_accuracy: 0.8325\n",
      "Epoch 47/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.9247\n",
      "Epoch 00047: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0391 - accuracy: 0.9247 - val_loss: 1.2359 - val_accuracy: 0.8133\n",
      "Epoch 48/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0364 - accuracy: 0.9252\n",
      "Epoch 00048: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 40s 52ms/step - loss: 1.0363 - accuracy: 0.9252 - val_loss: 1.2450 - val_accuracy: 0.8035\n",
      "Epoch 49/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0347 - accuracy: 0.9266\n",
      "Epoch 00049: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0347 - accuracy: 0.9266 - val_loss: 1.2354 - val_accuracy: 0.8163\n",
      "Epoch 50/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.9304\n",
      "Epoch 00050: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 1.0286 - accuracy: 0.9304 - val_loss: 1.2522 - val_accuracy: 0.8037\n",
      "Epoch 51/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0245 - accuracy: 0.9329\n",
      "Epoch 00051: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 1.0245 - accuracy: 0.9329 - val_loss: 1.2358 - val_accuracy: 0.8154\n",
      "Epoch 52/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0255 - accuracy: 0.9315\n",
      "Epoch 00052: val_accuracy did not improve from 0.83250\n",
      "782/782 [==============================] - 40s 52ms/step - loss: 1.0255 - accuracy: 0.9315 - val_loss: 1.2465 - val_accuracy: 0.8084\n",
      "Epoch 53/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.9340\n",
      "Epoch 00053: val_accuracy improved from 0.83250 to 0.83380, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 1.0212 - accuracy: 0.9340 - val_loss: 1.2056 - val_accuracy: 0.8338\n",
      "Epoch 54/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0204 - accuracy: 0.9351\n",
      "Epoch 00054: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0204 - accuracy: 0.9351 - val_loss: 1.2293 - val_accuracy: 0.8175\n",
      "Epoch 55/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0171 - accuracy: 0.9375\n",
      "Epoch 00055: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0171 - accuracy: 0.9375 - val_loss: 1.2384 - val_accuracy: 0.8112\n",
      "Epoch 56/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0139 - accuracy: 0.9382\n",
      "Epoch 00056: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0138 - accuracy: 0.9382 - val_loss: 1.2172 - val_accuracy: 0.8230\n",
      "Epoch 57/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0103 - accuracy: 0.9404\n",
      "Epoch 00057: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0103 - accuracy: 0.9404 - val_loss: 1.2288 - val_accuracy: 0.8169\n",
      "Epoch 58/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0103 - accuracy: 0.9392\n",
      "Epoch 00058: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 1.0103 - accuracy: 0.9392 - val_loss: 1.2516 - val_accuracy: 0.8077\n",
      "Epoch 59/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.9404\n",
      "Epoch 00059: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0084 - accuracy: 0.9404 - val_loss: 1.2467 - val_accuracy: 0.8050\n",
      "Epoch 60/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.9428\n",
      "Epoch 00060: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 1.0047 - accuracy: 0.9428 - val_loss: 1.2447 - val_accuracy: 0.8090\n",
      "Epoch 61/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0025 - accuracy: 0.9447\n",
      "Epoch 00061: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 1.0024 - accuracy: 0.9447 - val_loss: 1.2224 - val_accuracy: 0.8205\n",
      "Epoch 62/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0008 - accuracy: 0.9456\n",
      "Epoch 00062: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 1.0008 - accuracy: 0.9456 - val_loss: 1.2252 - val_accuracy: 0.8188\n",
      "Epoch 63/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9995 - accuracy: 0.9464\n",
      "Epoch 00063: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.9995 - accuracy: 0.9464 - val_loss: 1.2329 - val_accuracy: 0.8128\n",
      "Epoch 64/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.9486\n",
      "Epoch 00064: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.9960 - accuracy: 0.9486 - val_loss: 1.2270 - val_accuracy: 0.8218\n",
      "Epoch 65/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9934 - accuracy: 0.9500\n",
      "Epoch 00065: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.9934 - accuracy: 0.9500 - val_loss: 1.2234 - val_accuracy: 0.8198\n",
      "Epoch 66/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9937 - accuracy: 0.9492\n",
      "Epoch 00066: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9938 - accuracy: 0.9492 - val_loss: 1.2386 - val_accuracy: 0.8135\n",
      "Epoch 67/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9932 - accuracy: 0.9499\n",
      "Epoch 00067: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9932 - accuracy: 0.9499 - val_loss: 1.2170 - val_accuracy: 0.8216\n",
      "Epoch 68/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9881 - accuracy: 0.9520\n",
      "Epoch 00068: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.9881 - accuracy: 0.9520 - val_loss: 1.2448 - val_accuracy: 0.8119\n",
      "Epoch 69/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9890 - accuracy: 0.9527\n",
      "Epoch 00069: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.9890 - accuracy: 0.9527 - val_loss: 1.2108 - val_accuracy: 0.8268\n",
      "Epoch 70/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9871 - accuracy: 0.9525\n",
      "Epoch 00070: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.9871 - accuracy: 0.9525 - val_loss: 1.2112 - val_accuracy: 0.8291\n",
      "Epoch 71/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9838 - accuracy: 0.9547\n",
      "Epoch 00071: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.9838 - accuracy: 0.9547 - val_loss: 1.2437 - val_accuracy: 0.8142\n",
      "Epoch 72/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.9557\n",
      "Epoch 00072: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.9819 - accuracy: 0.9557 - val_loss: 1.2753 - val_accuracy: 0.7988\n",
      "Epoch 73/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9822 - accuracy: 0.9545\n",
      "Epoch 00073: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.9822 - accuracy: 0.9546 - val_loss: 1.2242 - val_accuracy: 0.8211\n",
      "Epoch 74/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9818 - accuracy: 0.9555\n",
      "Epoch 00074: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9818 - accuracy: 0.9555 - val_loss: 1.2233 - val_accuracy: 0.8229\n",
      "Epoch 75/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.9565\n",
      "Epoch 00075: val_accuracy did not improve from 0.83380\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9791 - accuracy: 0.9565 - val_loss: 1.2202 - val_accuracy: 0.8282\n",
      "Epoch 76/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.9595\n",
      "Epoch 00076: val_accuracy improved from 0.83380 to 0.83570, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.9744 - accuracy: 0.9595 - val_loss: 1.1995 - val_accuracy: 0.8357\n",
      "Epoch 77/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9759 - accuracy: 0.9591\n",
      "Epoch 00077: val_accuracy did not improve from 0.83570\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9759 - accuracy: 0.9591 - val_loss: 1.2110 - val_accuracy: 0.8292\n",
      "Epoch 78/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.9597\n",
      "Epoch 00078: val_accuracy did not improve from 0.83570\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.9740 - accuracy: 0.9597 - val_loss: 1.2071 - val_accuracy: 0.8338\n",
      "Epoch 79/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9745 - accuracy: 0.9585\n",
      "Epoch 00079: val_accuracy did not improve from 0.83570\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9746 - accuracy: 0.9585 - val_loss: 1.2147 - val_accuracy: 0.8307\n",
      "Epoch 80/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9703 - accuracy: 0.9615\n",
      "Epoch 00080: val_accuracy improved from 0.83570 to 0.84280, saving model to models\\resnet9.h5\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.9703 - accuracy: 0.9615 - val_loss: 1.1862 - val_accuracy: 0.8428\n",
      "Epoch 81/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.9605\n",
      "Epoch 00081: val_accuracy did not improve from 0.84280\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.9709 - accuracy: 0.9605 - val_loss: 1.2264 - val_accuracy: 0.8250\n",
      "Epoch 82/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9699 - accuracy: 0.9607\n",
      "Epoch 00082: val_accuracy did not improve from 0.84280\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.9699 - accuracy: 0.9607 - val_loss: 1.1980 - val_accuracy: 0.8350\n",
      "Epoch 83/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9689 - accuracy: 0.9612\n",
      "Epoch 00083: val_accuracy did not improve from 0.84280\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.9689 - accuracy: 0.9612 - val_loss: 1.2489 - val_accuracy: 0.8110\n",
      "Epoch 84/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.9646\n",
      "Epoch 00084: val_accuracy did not improve from 0.84280\n",
      "782/782 [==============================] - 39s 50ms/step - loss: 0.9646 - accuracy: 0.9646 - val_loss: 1.2487 - val_accuracy: 0.8127\n",
      "Epoch 85/200\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9642 - accuracy: 0.9641"
     ]
    }
   ],
   "source": [
    "# Run train and validation\n",
    "run_hist = train_test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test\n",
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.plot(run_hist.history['accuracy'], label='train')\n",
    "plt.plot(run_hist.history['val_accuracy'], label='test')\n",
    "plt.plot(run_hist.history['loss'], label='loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-8inf919-aDMhdl4N-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
