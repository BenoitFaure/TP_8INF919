{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n",
      "Number of classes:  10\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Print dimensions of training data\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "\n",
    "# Print dimensions of test data\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)\n",
    "\n",
    "# Print number of unique classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Number of classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images by 10 degrees\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,  # randomly shift images vertically by 10% of the height\n",
    "    zoom_range=0.1,  # randomly zoom images by 10%\n",
    "    horizontal_flip=True  # randomly flip images horizontally\n",
    ")\n",
    "\n",
    "data_gen_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the ImageDataGenerator on x_train\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # Generate augmented images\n",
    "# augmented_images = datagen.flow(x_train, y_train, batch_size=data_gen_batch_size)\n",
    "\n",
    "# # Iterate over the augmented images and append them to x_train\n",
    "# for i, (x_batch, y_batch) in enumerate(augmented_images):\n",
    "#     x_train = np.concatenate((x_train, x_batch), axis=0)\n",
    "#     y_train = np.concatenate((y_train, y_batch), axis=0)\n",
    "#     if i >= len(x_train) // data_gen_batch_size:\n",
    "#         break\n",
    "\n",
    "# # Print the new dimensions of x_train\n",
    "# print(\"New dimensions of x_train: \", x_train.shape)\n",
    "# print(\"New dimensions of y_train: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "resize = (224, 224)\n",
    "\n",
    "# One hot encode labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Load as tf dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Normalize images\n",
    "def normalize_img(image, label):\n",
    "\n",
    "    # Resize images\n",
    "    image = tf.image.resize(image, resize)\n",
    "\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Normalise images\n",
    "ds_train = train_dataset.map(normalize_img)\n",
    "ds_test = test_dataset.map(normalize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout, \\\n",
    "    AveragePooling2D, BatchNormalization, Activation, Add, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomZoom, RandomFlip, RandomTranslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initializer\n",
    "initializer = 'he_normal' # tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=42)\n",
    "classification_initializer = 'glorot_normal'\n",
    "\n",
    "activation_function = 'relu' # 'selu'\n",
    "use_bias = False # Batch Norm takes care of it\n",
    "epsilon_bn = 1.001e-5\n",
    "kernel_reg = None # tf.keras.regularizers.l1_l2(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resnet identity block\n",
    "\n",
    "def identity_block(filter, kernel_size=3):\n",
    "    def _identity_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "        \n",
    "        # Activation\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _identity_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resnet convolutional block\n",
    "\n",
    "def convolutional_res_block(filter, kernel_size=3):\n",
    "    def _convolutional_res_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Layer 3\n",
    "        input_x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(input_x)\n",
    "        input_x = BatchNormalization(axis=3, epsilon=epsilon_bn)(input_x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "        \n",
    "        # Activation\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _convolutional_res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduction Convolutional Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reduction convolutional block\n",
    "\n",
    "def reduction_convolutional_res_block(filter, kernel_size=3, strides=2):\n",
    "    def _reduction_convolutional_res_block(x):\n",
    "        input_x = x\n",
    "\n",
    "        # Layer 1\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "\n",
    "        # Layer 3\n",
    "        input_x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(input_x)\n",
    "        input_x = BatchNormalization(axis=3, epsilon=epsilon_bn)(input_x)\n",
    "\n",
    "        # Add Residue\n",
    "        x = Add()([x, input_x])\n",
    "\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _reduction_convolutional_res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block\n",
    "def convolutional_block(filter, kernel_size=3, strides=2):\n",
    "    def _convolutional_block(x):\n",
    "        \n",
    "        x = Conv2D(filter, kernel_size=kernel_size, \n",
    "                   padding = 'same', kernel_initializer=initializer,\n",
    "                   use_bias=use_bias, strides=strides, kernel_regularizer=kernel_reg)(x)\n",
    "        x = BatchNormalization(axis=3, epsilon=epsilon_bn)(x)\n",
    "        x = Activation(activation_function)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    return _convolutional_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = [\n",
    "    RandomRotation(0.3, seed=42),\n",
    "    RandomTranslation(0.4, 0.4, seed=42),\n",
    "    RandomZoom(0.3, seed=42),\n",
    "    RandomFlip(seed=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = [\n",
    "    RandomRotation(0.1, seed=42),\n",
    "    RandomTranslation(0.1, 0.1, seed=42),\n",
    "    RandomZoom(0.1, seed=42),\n",
    "    RandomFlip(seed=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_1_data_augmentation'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64),\n",
    "    identity_block(64),\n",
    "    reduction_convolutional_res_block(128),\n",
    "    identity_block(128),\n",
    "    reduction_convolutional_res_block(256),\n",
    "    identity_block(256),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    identity_block(512),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    reduction_convolutional_res_block(512),\n",
    "    AveragePooling2D(pool_size=4, strides=4, padding='same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_3'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64),\n",
    "    identity_block(64),\n",
    "    identity_block(64),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(128),\n",
    "    identity_block(128),\n",
    "    identity_block(128),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(256),\n",
    "    identity_block(256),\n",
    "    identity_block(256),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "    convolutional_res_block(512, kernel_size=1),\n",
    "    identity_block(512, kernel_size=1),\n",
    "    identity_block(512, kernel_size=1),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_4'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "    AveragePooling2D(pool_size=3, strides = 2, padding = 'same'),\n",
    "    \n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=(4, 4), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(512),\n",
    "    \n",
    "    convolutional_block(512, kernel_size = 3, strides = 2),\n",
    "    AveragePooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_small_tests'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "\n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=2, padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    AveragePooling2D(pool_size=2, padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=4, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_4_32'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "\n",
    "    identity_block(64),\n",
    "\n",
    "    AveragePooling2D(pool_size=(2, 2), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(128),\n",
    "\n",
    "    convolutional_res_block(256),\n",
    "\n",
    "    AveragePooling2D(pool_size=(4, 4), padding = 'same'),\n",
    "\n",
    "    convolutional_res_block(512),\n",
    "    \n",
    "    convolutional_block(512, kernel_size = 1, strides = 1),\n",
    "    AveragePooling2D(pool_size=2, strides = 2, padding = 'same'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet_5'\n",
    "\n",
    "conv_net = [\n",
    "    convolutional_block(64, kernel_size = 7, strides = 2),\n",
    "    MaxPooling2D(pool_size=3, strides = 2, padding = 'same'),\n",
    "\n",
    "    identity_block(64),\n",
    "    identity_block(64),\n",
    "\n",
    "    convolutional_block(128),\n",
    "    identity_block(128),\n",
    "\n",
    "    convolutional_block(256),\n",
    "    identity_block(256),\n",
    "\n",
    "    convolutional_block(512),\n",
    "    identity_block(512),\n",
    "\n",
    "    AveragePooling2D(pool_size=7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_name = None\n",
    "if False:\n",
    "    model_name = 'resnet_4_1'\n",
    "    load_model_name = 'resnet_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_net = [\n",
    "    Flatten(),\n",
    "    Dense(512, kernel_initializer=initializer, activation=activation_function),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, kernel_initializer=classification_initializer, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile mondel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "input_shape = (resize[0], resize[1], 3)\n",
    "input_layer = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "\n",
    "    def compile_layers(input, layers):\n",
    "        for layer in layers:\n",
    "            input = layer(input)\n",
    "        return input\n",
    "    \n",
    "    # Build Data augmentation\n",
    "    data_augmentation_layers = compile_layers(input_layer, data_aug)\n",
    "\n",
    "    # Build Feature Extractor\n",
    "    conv_net_layers = compile_layers(data_augmentation_layers, conv_net)\n",
    "\n",
    "    # Build Classifier\n",
    "    classification_layers = compile_layers(conv_net_layers, classification_net)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=classification_layers)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model_name is not None:\n",
    "    model.load_weights('models/' + load_model_name + '.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "random_rotation_1 (RandomRotati (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "random_translation_1 (RandomTra (None, 224, 224, 3)  0           random_rotation_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "random_zoom_1 (RandomZoom)      (None, 224, 224, 3)  0           random_translation_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "random_flip_1 (RandomFlip)      (None, 224, 224, 3)  0           random_zoom_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        random_flip_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 64)   36864       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 64)   36864       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 128)  73856       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 128)  147456      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 128)  147456      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 128)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 256)  295168      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 256)  589824      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 256)  589824      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 14, 14, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 512)    1180160     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 512)    2359296     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 512)    2359296     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 7, 7, 512)    0           batch_normalization_13[0][0]     \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 1, 1, 512)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,179,082\n",
      "Trainable params: 8,173,066\n",
      "Non-trainable params: 6,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train settings\n",
    "epochs = 200\n",
    "batch_size = 64 # 8\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 0.005\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset for Performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# ds_train = ds_train.cache()\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "del x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(label_smoothing=0.2), metrics=['accuracy'])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < 50:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "\n",
    "    # Save model callback\n",
    "    checkpoint = ModelCheckpoint('models/' + model_name + '.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "    # Tensorboard callback\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_' + model_name\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    print('tensorboard --logdir ' + log_dir)\n",
    "\n",
    "    # Train model\n",
    "    run_hist = model.fit(ds_train, validation_data=ds_test,\n",
    "                         epochs=epochs, batch_size=batch_size, \n",
    "                         \n",
    "                         callbacks=[checkpoint, tensorboard_callback])\n",
    "    \n",
    "    return run_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir logs/fit/20231123-190252_resnet_5\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/782 [..............................] - ETA: 0s - loss: 3.2872 - accuracy: 0.0469WARNING:tensorflow:From c:\\Users\\benoi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tp-8inf919-aDMhdl4N-py3.8\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.1789 - accuracy: 0.2162\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.18630, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 195s 249ms/step - loss: 2.1789 - accuracy: 0.2162 - val_loss: 2.2511 - val_accuracy: 0.1863\n",
      "Epoch 2/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.0412 - accuracy: 0.2877\n",
      "Epoch 00002: val_accuracy improved from 0.18630 to 0.31000, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 2.0412 - accuracy: 0.2877 - val_loss: 2.0136 - val_accuracy: 0.3100\n",
      "Epoch 3/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.9450 - accuracy: 0.3567\n",
      "Epoch 00003: val_accuracy improved from 0.31000 to 0.36800, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 196s 250ms/step - loss: 1.9450 - accuracy: 0.3567 - val_loss: 1.9299 - val_accuracy: 0.3680\n",
      "Epoch 4/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.8423 - accuracy: 0.4459\n",
      "Epoch 00004: val_accuracy improved from 0.36800 to 0.45480, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.8423 - accuracy: 0.4459 - val_loss: 1.8239 - val_accuracy: 0.4548\n",
      "Epoch 5/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.7570 - accuracy: 0.5067\n",
      "Epoch 00005: val_accuracy improved from 0.45480 to 0.47940, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.7570 - accuracy: 0.5067 - val_loss: 1.7475 - val_accuracy: 0.4794\n",
      "Epoch 6/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.6900 - accuracy: 0.5535\n",
      "Epoch 00006: val_accuracy improved from 0.47940 to 0.61510, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.6900 - accuracy: 0.5535 - val_loss: 1.5708 - val_accuracy: 0.6151\n",
      "Epoch 7/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.6304 - accuracy: 0.5929\n",
      "Epoch 00007: val_accuracy did not improve from 0.61510\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.6304 - accuracy: 0.5929 - val_loss: 1.6102 - val_accuracy: 0.5869\n",
      "Epoch 8/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.5780 - accuracy: 0.6258\n",
      "Epoch 00008: val_accuracy did not improve from 0.61510\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.5780 - accuracy: 0.6258 - val_loss: 1.5718 - val_accuracy: 0.6074\n",
      "Epoch 9/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.5266 - accuracy: 0.6589\n",
      "Epoch 00009: val_accuracy improved from 0.61510 to 0.68140, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.5266 - accuracy: 0.6589 - val_loss: 1.4523 - val_accuracy: 0.6814\n",
      "Epoch 10/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.6874\n",
      "Epoch 00010: val_accuracy improved from 0.68140 to 0.70690, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.4805 - accuracy: 0.6874 - val_loss: 1.4089 - val_accuracy: 0.7069\n",
      "Epoch 11/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.4452 - accuracy: 0.7106\n",
      "Epoch 00011: val_accuracy improved from 0.70690 to 0.73350, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.4452 - accuracy: 0.7106 - val_loss: 1.3658 - val_accuracy: 0.7335\n",
      "Epoch 12/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.4050 - accuracy: 0.7328\n",
      "Epoch 00012: val_accuracy did not improve from 0.73350\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.4050 - accuracy: 0.7328 - val_loss: 1.4189 - val_accuracy: 0.7068\n",
      "Epoch 13/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3729 - accuracy: 0.7546\n",
      "Epoch 00013: val_accuracy did not improve from 0.73350\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.3729 - accuracy: 0.7546 - val_loss: 1.3835 - val_accuracy: 0.7161\n",
      "Epoch 14/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3446 - accuracy: 0.7685\n",
      "Epoch 00014: val_accuracy improved from 0.73350 to 0.76210, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.3446 - accuracy: 0.7685 - val_loss: 1.3144 - val_accuracy: 0.7621\n",
      "Epoch 15/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3167 - accuracy: 0.7870\n",
      "Epoch 00015: val_accuracy improved from 0.76210 to 0.77200, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.3167 - accuracy: 0.7870 - val_loss: 1.2919 - val_accuracy: 0.7720\n",
      "Epoch 16/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2947 - accuracy: 0.7996\n",
      "Epoch 00016: val_accuracy improved from 0.77200 to 0.78200, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 186s 238ms/step - loss: 1.2947 - accuracy: 0.7996 - val_loss: 1.2863 - val_accuracy: 0.7820\n",
      "Epoch 17/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2720 - accuracy: 0.8097\n",
      "Epoch 00017: val_accuracy did not improve from 0.78200\n",
      "782/782 [==============================] - 194s 248ms/step - loss: 1.2720 - accuracy: 0.8097 - val_loss: 1.2841 - val_accuracy: 0.7784\n",
      "Epoch 18/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2544 - accuracy: 0.8218\n",
      "Epoch 00018: val_accuracy improved from 0.78200 to 0.80020, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 192s 246ms/step - loss: 1.2544 - accuracy: 0.8218 - val_loss: 1.2493 - val_accuracy: 0.8002\n",
      "Epoch 19/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2416 - accuracy: 0.8297\n",
      "Epoch 00019: val_accuracy improved from 0.80020 to 0.81960, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 201s 257ms/step - loss: 1.2416 - accuracy: 0.8297 - val_loss: 1.2122 - val_accuracy: 0.8196\n",
      "Epoch 20/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2230 - accuracy: 0.8388\n",
      "Epoch 00020: val_accuracy did not improve from 0.81960\n",
      "782/782 [==============================] - 196s 251ms/step - loss: 1.2230 - accuracy: 0.8388 - val_loss: 1.2498 - val_accuracy: 0.7974\n",
      "Epoch 21/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.2117 - accuracy: 0.8467\n",
      "Epoch 00021: val_accuracy improved from 0.81960 to 0.83520, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 195s 249ms/step - loss: 1.2117 - accuracy: 0.8467 - val_loss: 1.1860 - val_accuracy: 0.8352\n",
      "Epoch 22/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1948 - accuracy: 0.8545\n",
      "Epoch 00022: val_accuracy did not improve from 0.83520\n",
      "782/782 [==============================] - 195s 250ms/step - loss: 1.1948 - accuracy: 0.8545 - val_loss: 1.2396 - val_accuracy: 0.8131\n",
      "Epoch 23/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1867 - accuracy: 0.8601\n",
      "Epoch 00023: val_accuracy improved from 0.83520 to 0.83890, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 194s 248ms/step - loss: 1.1867 - accuracy: 0.8601 - val_loss: 1.1795 - val_accuracy: 0.8389\n",
      "Epoch 24/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1766 - accuracy: 0.8658\n",
      "Epoch 00024: val_accuracy did not improve from 0.83890\n",
      "782/782 [==============================] - 189s 241ms/step - loss: 1.1766 - accuracy: 0.8658 - val_loss: 1.2267 - val_accuracy: 0.8127\n",
      "Epoch 25/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1655 - accuracy: 0.8718\n",
      "Epoch 00025: val_accuracy did not improve from 0.83890\n",
      "782/782 [==============================] - 193s 246ms/step - loss: 1.1655 - accuracy: 0.8718 - val_loss: 1.2488 - val_accuracy: 0.8024\n",
      "Epoch 26/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1582 - accuracy: 0.8755\n",
      "Epoch 00026: val_accuracy did not improve from 0.83890\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.1582 - accuracy: 0.8755 - val_loss: 1.2030 - val_accuracy: 0.8239\n",
      "Epoch 27/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1487 - accuracy: 0.8814\n",
      "Epoch 00027: val_accuracy did not improve from 0.83890\n",
      "782/782 [==============================] - 185s 237ms/step - loss: 1.1487 - accuracy: 0.8814 - val_loss: 1.2007 - val_accuracy: 0.8282\n",
      "Epoch 28/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1367 - accuracy: 0.8868\n",
      "Epoch 00028: val_accuracy improved from 0.83890 to 0.84340, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 186s 237ms/step - loss: 1.1367 - accuracy: 0.8868 - val_loss: 1.1676 - val_accuracy: 0.8434\n",
      "Epoch 29/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1258 - accuracy: 0.8945\n",
      "Epoch 00029: val_accuracy did not improve from 0.84340\n",
      "782/782 [==============================] - 185s 237ms/step - loss: 1.1258 - accuracy: 0.8945 - val_loss: 1.1973 - val_accuracy: 0.8324\n",
      "Epoch 30/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1186 - accuracy: 0.8975\n",
      "Epoch 00030: val_accuracy improved from 0.84340 to 0.84930, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 186s 237ms/step - loss: 1.1186 - accuracy: 0.8975 - val_loss: 1.1530 - val_accuracy: 0.8493\n",
      "Epoch 31/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1134 - accuracy: 0.9010\n",
      "Epoch 00031: val_accuracy did not improve from 0.84930\n",
      "782/782 [==============================] - 183s 235ms/step - loss: 1.1134 - accuracy: 0.9010 - val_loss: 1.1749 - val_accuracy: 0.8447\n",
      "Epoch 32/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.9017\n",
      "Epoch 00032: val_accuracy did not improve from 0.84930\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.1088 - accuracy: 0.9017 - val_loss: 1.1915 - val_accuracy: 0.8330\n",
      "Epoch 33/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.1024 - accuracy: 0.9075\n",
      "Epoch 00033: val_accuracy did not improve from 0.84930\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.1024 - accuracy: 0.9075 - val_loss: 1.1715 - val_accuracy: 0.8466\n",
      "Epoch 34/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0931 - accuracy: 0.9120\n",
      "Epoch 00034: val_accuracy improved from 0.84930 to 0.85650, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 188s 240ms/step - loss: 1.0931 - accuracy: 0.9120 - val_loss: 1.1568 - val_accuracy: 0.8565\n",
      "Epoch 35/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0896 - accuracy: 0.9128\n",
      "Epoch 00035: val_accuracy improved from 0.85650 to 0.86410, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 185s 237ms/step - loss: 1.0896 - accuracy: 0.9128 - val_loss: 1.1376 - val_accuracy: 0.8641\n",
      "Epoch 36/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0844 - accuracy: 0.9167\n",
      "Epoch 00036: val_accuracy did not improve from 0.86410\n",
      "782/782 [==============================] - 188s 240ms/step - loss: 1.0844 - accuracy: 0.9167 - val_loss: 1.1634 - val_accuracy: 0.8503\n",
      "Epoch 37/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0770 - accuracy: 0.9205\n",
      "Epoch 00037: val_accuracy improved from 0.86410 to 0.86480, saving model to models\\resnet_5.h5\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.0770 - accuracy: 0.9205 - val_loss: 1.1310 - val_accuracy: 0.8648\n",
      "Epoch 38/200\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.9210"
     ]
    }
   ],
   "source": [
    "# Run train and validation\n",
    "run_hist = train_test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test\n",
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.plot(run_hist.history['accuracy'], label='train')\n",
    "plt.plot(run_hist.history['val_accuracy'], label='test')\n",
    "plt.plot(run_hist.history['loss'], label='loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp-8inf919-aDMhdl4N-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
